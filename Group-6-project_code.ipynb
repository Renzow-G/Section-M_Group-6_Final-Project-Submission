{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f03aedf-5c3b-44a8-aec8-8a2ace084ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user name:  omamori\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_14720\\2422878691.py:378: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = diary_df.groupby('Release Year')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              movie title  Release Year  Rating  \\\n",
      "0                               Midsommar          2019    3.78   \n",
      "1                             Jojo Rabbit          2019    4.03   \n",
      "2              Killers of the Flower Moon          2023    4.09   \n",
      "3       Everything Everywhere All at Once          2022    4.30   \n",
      "4                        The Green Knight          2021    3.69   \n",
      "5   Eternal Sunshine of the Spotless Mind          2004    4.25   \n",
      "6                    Inglourious Basterds          2009    4.34   \n",
      "7                       Pride & Prejudice          2005    4.10   \n",
      "8              Captain America: Civil War          2016    3.58   \n",
      "9                          BlacKkKlansman          2018    3.94   \n",
      "10                                    Big          1988    3.59   \n",
      "11                            The Pianist          2002    4.37   \n",
      "12                              True Lies          1994    3.58   \n",
      "13                All the President's Men          1976    4.16   \n",
      "14                           Time Bandits          1981    3.54   \n",
      "\n",
      "                                               Genres  \\\n",
      "0                            [Mystery, Drama, Horror]   \n",
      "1                                [War, Drama, Comedy]   \n",
      "2                             [History, Crime, Drama]   \n",
      "3        [Science Fiction, Adventure, Comedy, Action]   \n",
      "4                         [Adventure, Fantasy, Drama]   \n",
      "5                   [Science Fiction, Romance, Drama]   \n",
      "6                              [Drama, Thriller, War]   \n",
      "7                                    [Drama, Romance]   \n",
      "8                [Action, Science Fiction, Adventure]   \n",
      "9                              [Drama, Comedy, Crime]   \n",
      "10          [Drama, Comedy, Fantasy, Romance, Family]   \n",
      "11                                       [Drama, War]   \n",
      "12                                 [Thriller, Action]   \n",
      "13                [Thriller, Mystery, History, Drama]   \n",
      "14  [Family, Science Fiction, Fantasy, Comedy, Adv...   \n",
      "\n",
      "                                         movie review  \\\n",
      "0   Sure, it has just as much to say about our ign...   \n",
      "1   It relentlessly mocks not only the disgusting ...   \n",
      "2   By its final act, when youâ€™ve journeyed throug...   \n",
      "3   tâ€™s so very funny, sweet, and gross in the bes...   \n",
      "4   The Green Knight is a cinema experience like f...   \n",
      "5   ...giving us an ending that is more painfully ...   \n",
      "6   The quotes and tributes to other films are sti...   \n",
      "7                 No reviews found on Rotten Tomatoes   \n",
      "8   The airport battle is still one of the best sc...   \n",
      "9   It becomes painfully and chillingly obvious ho...   \n",
      "10  Big is warm-hearted and sweet without ever los...   \n",
      "11                No reviews found on Rotten Tomatoes   \n",
      "12  'True Lies' is a James Bond fantasy mixed with...   \n",
      "13  It's superbly directed on every level, but the...   \n",
      "14  a funny, weird cameo-filled caper that finds v...   \n",
      "\n",
      "                                          review link people_watched  \\\n",
      "0          https://www.rottentomatoes.com/m/midsommar      2,979,411   \n",
      "1        https://www.rottentomatoes.com/m/jojo_rabbit      1,997,519   \n",
      "2   https://www.rottentomatoes.com/m/killers_of_th...      1,005,879   \n",
      "3   https://www.rottentomatoes.com/m/everything_ev...      3,028,580   \n",
      "4   https://www.rottentomatoes.com/m/the_green_knight        543,289   \n",
      "5   https://www.rottentomatoes.com/m/eternal_sunsh...      2,446,123   \n",
      "6   https://www.rottentomatoes.com/m/inglourious_b...      2,731,299   \n",
      "7                                                None      1,343,915   \n",
      "8   https://www.rottentomatoes.com/m/captain_ameri...      2,252,435   \n",
      "9     https://www.rottentomatoes.com/m/blackkklansman      1,154,262   \n",
      "10               https://www.rottentomatoes.com/m/big        439,869   \n",
      "11           https://www.rottentomatoes.com/m/pianist      1,003,019   \n",
      "12         https://www.rottentomatoes.com/m/true_lies        217,103   \n",
      "13  https://www.rottentomatoes.com/m/all_the_presi...        196,262   \n",
      "14      https://www.rottentomatoes.com/m/time_bandits         92,232   \n",
      "\n",
      "                                Language  \n",
      "0                     {Swedish, English}  \n",
      "1                      {German, English}  \n",
      "2               {Latin, English, French}  \n",
      "3          {Cantonese, Chinese, English}  \n",
      "4                              {English}  \n",
      "5                              {English}  \n",
      "6     {German, Italian, English, French}  \n",
      "7                              {English}  \n",
      "8   {German, Romanian, Russian, English}  \n",
      "9                              {English}  \n",
      "10                             {English}  \n",
      "11    {German, Russian, English, Polish}  \n",
      "12     {German, Arabic, English, French}  \n",
      "13                    {English, Spanish}  \n",
      "14                             {English}  \n",
      "773.4665207862854\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import time\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "# VARIABLES\n",
    "all_genres = ['action','adventure','animation','comedy','crime','documentary','drama','family','fantasy','history','horror','music','mystery','romance','science fiction','thriller','tv movie','war','western']\n",
    "top_genres = {\n",
    "    'action': 0,\n",
    "    'adventure': 0,\n",
    "    'animation': 0,\n",
    "    'comedy': 0,\n",
    "    'crime': 0,\n",
    "    'documentary': 0,\n",
    "    'drama': 0,\n",
    "    'family': 0,\n",
    "    'fantasy': 0,\n",
    "    'history': 0,\n",
    "    'horror': 0,\n",
    "    'music': 0,\n",
    "    'mystery': 0,\n",
    "    'romance': 0,\n",
    "    'science fiction': 0,\n",
    "    'thriller': 0,\n",
    "    'tv movie': 0,\n",
    "    'war': 0,\n",
    "    'western': 0\n",
    "}\n",
    "list_urls = []\n",
    "titles = []\n",
    "ratings_list = []\n",
    "release_years = []\n",
    "data = {}\n",
    "\n",
    "# GETTING THE URLS\n",
    "## First Page\n",
    "base_url = 'https://letterboxd.com'\n",
    "user_name = input('Enter user name: ')\n",
    "r = requests.get(f'{base_url}/{user_name}/films/diary/')\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "list_urls = [base_url + a.get('href') for a in soup.select('h3>a[href]')]\n",
    "if list_urls == []:\n",
    "    print('No films found')\n",
    "    sys.exit(1)\n",
    "## Subsequent Pages\n",
    "links = soup.find_all('li', class_=\"paginate-page\")\n",
    "try:\n",
    "    start_character = str(links[-1]).find('/page/') + 6\n",
    "    end_character = str(links[-1]).find('/\">')\n",
    "    end_page = int(str(links[-1])[start_character:end_character])\n",
    "except IndexError:\n",
    "    end_page = 1\n",
    "if end_page >1:\n",
    "    for page in range(2, end_page + 1):\n",
    "        r = requests.get(f'{base_url}/{user_name}/films/diary/page/{page}')\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        new_urls = [base_url + a.get('href') for a in soup.select('h3>a[href]')]\n",
    "        list_urls.extend(new_urls)\n",
    "\n",
    "# GETTING THE TITLES, RELEASE YEAR, RATINGS, AND GENRES + DATA FORMATTING\n",
    "for url in list_urls:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    ## Getting the Titles and Release Year\n",
    "    span = soup.find_all('span', class_=\"film-title-wrapper\")\n",
    "    span_soup = BeautifulSoup('\\n'.join(map(str, span)))\n",
    "    a_list = list(span_soup.find_all('a'))\n",
    "    count = 0\n",
    "    for a in a_list:\n",
    "        a_str =str(a)\n",
    "        start_chr = a_str.find('\">')+2\n",
    "        end_chr = a_str.find(\"</\")\n",
    "        count += 1\n",
    "        if count == 1:\n",
    "            titles.append(a_str[start_chr:end_chr])\n",
    "        if count == 2:\n",
    "            release_years.append(a_str[start_chr:end_chr])\n",
    "        if count == 3:\n",
    "            print('uh oh, Error at titles/year')\n",
    "            break\n",
    "    ## Getting the Ratings\n",
    "    script_str = str(soup.find_all('script', type=\"application/ld+json\"))\n",
    "    start_chr = script_str.find('\"ratingValue\":')+14\n",
    "    end_chr = script_str.find(',\"worstRating\"')\n",
    "    if end_chr == -1:\n",
    "        ratings_list.append('null')\n",
    "        continue\n",
    "    ratings_list.append(script_str[start_chr:end_chr])\n",
    "    ## Getting the Genres\n",
    "    all_script_tags = soup.find_all(\"script\")\n",
    "    script_list = []\n",
    "    movie_genres = []\n",
    "    for i in all_script_tags:\n",
    "        script_list.append(str(i))\n",
    "    raw_script_tag = script_list[-1]\n",
    "    for i in all_genres:\n",
    "        if i in raw_script_tag:\n",
    "            movie_genres.append(i)\n",
    "            top_genres[i] += 1\n",
    "    ## Formatting the Data Dictionary\n",
    "    if titles[-1] not in data:\n",
    "        data[titles[-1]] = [release_years[-1],ratings_list[-1], movie_genres]\n",
    "\n",
    "# SORTING GENRE VALUES\n",
    "sorted_top_genres = sorted(top_genres.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "top_3 = [genre for genre, count in sorted_top_genres[:3]]\n",
    "\n",
    "soup = BeautifulSoup('', 'html.parser')\n",
    "\n",
    "# use webdriver to open letterboxd based on rating and genre\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# get soup of all genres combined\n",
    "driver.get(f\"https://letterboxd.com/films/genre/{'+'.join(top_3)}/\")\n",
    "time.sleep(1)\n",
    "html_doc = driver.page_source\n",
    "soup1 = BeautifulSoup(html_doc, 'html.parser')\n",
    "soup.extend(soup1.contents)\n",
    "time.sleep(0.5)\n",
    "# get soup of each genre separately\n",
    "for i in [0,1,2]:\n",
    "    for j in ['NA', 'page/2/']: # page2 for more data\n",
    "        soup2 = j\n",
    "        if j == 'NA':\n",
    "            driver.get(f\"https://letterboxd.com/films/genre/{top_3[i]}/\")\n",
    "        else:\n",
    "            driver.get(f\"https://letterboxd.com/films/genre/{top_3[i]}/{j}\")\n",
    "        time.sleep(1)\n",
    "        html_doc = driver.page_source\n",
    "        soup2 = BeautifulSoup(html_doc, 'html.parser')\n",
    "        soup.extend(soup2.contents)\n",
    "        time.sleep(0.5)\n",
    "# get soup of old movies\n",
    "for i in [0,1,2]:\n",
    "    for j in ['9','8','7']: # old movies\n",
    "        soup2 = j\n",
    "        driver.get(f\"https://letterboxd.com/films/popular/decade/19{j}0s/genre/{top_3[i]}/\")\n",
    "        time.sleep(1)\n",
    "        html_doc = driver.page_source\n",
    "        soup2 = BeautifulSoup(html_doc, 'html.parser')\n",
    "        soup.extend(soup2.contents)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# parse out the tags that have the film info\n",
    "initial_poster_lists = soup.find_all('li', class_='listitem poster-container')\n",
    "\n",
    "# removes duplicate entries\n",
    "poster_lists = list(OrderedDict.fromkeys(initial_poster_lists))\n",
    "\n",
    "# get the url\n",
    "url_list = []\n",
    "for poster in poster_lists:\n",
    "    link_tag = poster.find('div')\n",
    "    link_url = link_tag['data-poster-url'].replace('image-150/','')\n",
    "    url_list.append(f'https://letterboxd.com{link_url}')\n",
    "\n",
    "# get the title, date, and rating string\n",
    "title_date_ratingS = []\n",
    "for poster in poster_lists:\n",
    "    info_tag = poster.find('a')\n",
    "    title_date_rating = info_tag['data-original-title']\n",
    "    title_date_ratingS.append(title_date_rating)\n",
    "\n",
    "# get the title and rating, then put in a dictionary\n",
    "title_rating_dict = {}\n",
    "pattern = r\"([^\\(]+) \\((\\d{4})\\) ([\\d.]+)\"\n",
    "for info in title_date_ratingS:\n",
    "    match = re.search(pattern, info)\n",
    "    title = match.group(1)\n",
    "    release = match.group(2)\n",
    "    rating = match.group(3)\n",
    "    if title in title_rating_dict.keys():\n",
    "        title += '1'\n",
    "        title_rating_dict[title] = [release, rating]\n",
    "    else:\n",
    "        title_rating_dict[title] = [release, rating]\n",
    "\n",
    "# function to get genre and theme\n",
    "def scrape_url(url):\n",
    "    response = requests.get(url).content\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    # Extract the desired data from the soup object\n",
    "    genre_theme_tags = soup.find_all('a', {'href': re.compile(r'/films/genre/(.+)')}) # if want themes: (genre|theme)\n",
    "    listt = []\n",
    "    for tag in genre_theme_tags:\n",
    "        genre_theme = tag.text\n",
    "        listt.append(genre_theme)\n",
    "    return listt\n",
    "\n",
    "# Use concurrent.futures to make all the requests in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    genre_theme_lists = list(executor.map(scrape_url, url_list))\n",
    "\n",
    "for i in range(len(title_rating_dict)):\n",
    "    title_rating_dict[list(title_rating_dict.keys())[i]] += [genre_theme_lists[i]]\n",
    "\n",
    "# convert title_rating_dict to dataframe\n",
    "search_results_df = pd.DataFrame(title_rating_dict).T\n",
    "search_results_df = search_results_df.rename(columns={0: 'Release Year', 1: 'Rating', 2: 'Genres'})\n",
    "search_results_df['movie_url'] = url_list\n",
    "sorted_search_df = search_results_df.sort_values(by=['Rating'], ascending=False)\n",
    "sorted_search_df.reset_index(inplace=True)\n",
    "sorted_search_df = sorted_search_df.rename(columns={'index':'movie title'})\n",
    "\n",
    "sorted_search_df['Rating'] = sorted_search_df['Rating'].astype(float)\n",
    "sorted_search_df['Release Year'] = sorted_search_df['Release Year'].astype(int)\n",
    "\n",
    "#  ====================================================\n",
    "\n",
    "# remove watched\n",
    "search_results_df1=sorted_search_df.copy()\n",
    "diary=list(data.keys())\n",
    "for entry in diary:\n",
    "    if entry in list(search_results_df1[\"movie title\"]):\n",
    "        search_results_df1=search_results_df1.drop(search_results_df1[search_results_df1[\"movie title\"]==entry].index)\n",
    "\n",
    "def get_rotten_tomatoes_url(movie_name, year):\n",
    "    year=str(year)\n",
    "    query = urllib.parse.quote(movie_name)\n",
    "    url = f\"https://www.rottentomatoes.com/search?search={query}\"\n",
    "    response = requests.get(url)\n",
    "    movie=response.text\n",
    "    soup = BeautifulSoup(movie, 'html.parser')\n",
    "    URLS=soup.find_all('a',class_='unset')\n",
    "    a=[]\n",
    "    links=[]\n",
    "    dates=[]\n",
    "    titles=[]\n",
    "    x=0\n",
    "    y=0\n",
    "    parse_title=[\"/n\",\" \"]\n",
    "    for tag in URLS:\n",
    "        if \"thumbnail\" in str(tag):\n",
    "            a.append(tag)\n",
    "    for tag in a:\n",
    "        links.append(str(tag)[str(tag).find(\"https\"):(str(tag).find(\" slot\")-1)])\n",
    "    datetag=soup.find_all('search-page-media-row')\n",
    "    for tag in datetag:\n",
    "        dates.append(str(tag)[str(tag).find(\"releaseyear\")+13:str(tag).find(\"releaseyear\")+17])\n",
    "    while x!=len(datetag):\n",
    "        lee=datetag[x].text.replace(\"\\n\",\"\")\n",
    "        lee=lee.replace(\"  \",\"\")\n",
    "        titles.append(lee)\n",
    "        x+=1\n",
    "    while y!=len(datetag):\n",
    "        if dates[y]==year and titles[y]==movie_name:\n",
    "            return links[y]\n",
    "        y+=1\n",
    "\n",
    "def get_movie_reviews(movie_title):\n",
    "    unnecessary_punctuation_second = r\"$@[].,'#()-\\\"!?â€™_;:/â€¦\"\n",
    "    y=0\n",
    "    clean_movie=movie_title\n",
    "    while y!=len(unnecessary_punctuation_second):\n",
    "        clean_movie=clean_movie.replace(unnecessary_punctuation_second[y],\"\")\n",
    "        y+=1\n",
    "    movie_string=clean_movie.split()\n",
    "    x=0\n",
    "    Movie=\"\"\n",
    "    while x!=len(movie_string):\n",
    "        Movie+=movie_string[x]\n",
    "        if x==len(movie_string)-1:\n",
    "            \"\"\n",
    "        else:\n",
    "            Movie+=\"_\"\n",
    "        x+=1\n",
    "    z=0\n",
    "    url = f\"https://www.rottentomatoes.com/m/{Movie}/reviews\"\n",
    "    response = requests.get(url)\n",
    "    reviews=response.text\n",
    "    soup = BeautifulSoup(reviews, 'html.parser')\n",
    "    presented_review=soup.find_all('p',class_='review-text')[z].text\n",
    "    review_critic=soup.find_all('a',class_='display-name')[z].text\n",
    "    score=soup.find_all('score-icon-critics')\n",
    "    tag=0\n",
    "    number=len(score)\n",
    "    score1=score.copy()\n",
    "    while tag!=number:\n",
    "        if \"4\" not in str(score1[tag]):\n",
    "            score.remove(score1[tag])\n",
    "        else:\n",
    "            break\n",
    "        tag+=1\n",
    "    score\n",
    "    score2=score[z]\n",
    "    senti=str(score2)\n",
    "    parse_critics = [\"\\n\",\"  \"]\n",
    "    punct=0\n",
    "    space=0\n",
    "    while \"NEGATIVE\" in senti:\n",
    "        z+=1\n",
    "        score2=score[z]\n",
    "        senti=str(score2)\n",
    "        presented_review=soup.find_all('p',class_='review-text')[z].text\n",
    "        review_critic=soup.find_all('a',class_='display-name')[z].text\n",
    "        \n",
    "    while punct!=len(parse_critics):\n",
    "            review_critic=review_critic.replace(parse_critics[punct],\"\")\n",
    "            punct+=1\n",
    "    while space!=len(parse_critics):\n",
    "            presented_review=presented_review.replace(parse_critics[space],\" \")\n",
    "            space+=1\n",
    "    return presented_review+\" (\"+review_critic+\", Rotten Tomatoes)\"\n",
    "    \n",
    "    \n",
    "def movie_reception(function, movie_title, year): #MAIN FUNCTION\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    year=str(year)\n",
    "    try:\n",
    "        movie_title1=movie_title \n",
    "        unnecessary_punctuation_first = r\"$@[].,'#()-\\\"!?â€™_;:/â€¦\"\n",
    "        y=0\n",
    "        while y!=len(unnecessary_punctuation_first):\n",
    "            movie_title1=movie_title1.replace(unnecessary_punctuation_first[y],\" \")\n",
    "            y+=1   \n",
    "        movie_title1=movie_title1.replace(\"&\",'and')\n",
    "        movie_copy=movie_title1\n",
    "        movie_title1=movie_title1+\" \"+year\n",
    "        try:\n",
    "            return function(movie_title1)\n",
    "        except Exception:      \n",
    "            return function(movie_copy)\n",
    "    except Exception:\n",
    "        movie_title2=movie_title\n",
    "        movie_title2=movie_title2.replace(\"&\",'and')\n",
    "        movie_copy=movie_title2\n",
    "        movie_title2=movie_title2+\" \"+year\n",
    "        try:\n",
    "            return function(movie_title2)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return function(movie_copy)\n",
    "            except Exception:\n",
    "                if function==get_movie_reviews:\n",
    "                    return \"No reviews found on Rotten Tomatoes\"\n",
    "                else:\n",
    "                    return \"not a valid function\"\n",
    "\n",
    "# convert diary dictionary to dataframe\n",
    "diary_df = pd.DataFrame(data).T\n",
    "diary_df = diary_df.rename(columns={0: 'Release Year', 1: 'Rating', 2: 'Genres'})\n",
    "diary_df['Release Year'] = diary_df['Release Year'].astype(int)\n",
    "current_year = datetime.now().year\n",
    "edited_year = pd.cut(diary_df['Release Year'], \n",
    "              bins=[1899, current_year - 21, current_year - 6, current_year],\n",
    "              labels=['old', 'notsorecent', 'recent'])\n",
    "diary_df['Release Year'] = edited_year\n",
    "\n",
    "# Function to recommend 15 random movies\n",
    "def recommend_movies(df):\n",
    "    # Filter the DataFrame by Year\n",
    "    recent_movies = df[df['Release Year'] >= current_year - 5]\n",
    "    notsorecent_movies = df[(df['Release Year'] < current_year - 5) & (df['Release Year'] >= current_year - 20)]\n",
    "    old_movies = df[df['Release Year'] < current_year - 20]\n",
    "    \n",
    "    # Filter the DataFrame to only include movies with a rating of 3.5 or higher\n",
    "    high_rated_movies1 = recent_movies[recent_movies['Rating'] >= 3.5]\n",
    "    high_rated_movies2 = notsorecent_movies[notsorecent_movies['Rating'] >= 3.5]\n",
    "    high_rated_movies3 = old_movies[old_movies['Rating'] >= 3.5]\n",
    "    \n",
    "    grouped = diary_df.groupby('Release Year')\n",
    "\n",
    "    # calculate percentage of movies from the 3 'periods'\n",
    "    recent_num = round((int(len(grouped.get_group('recent'))) / len(diary_df)) * 15)\n",
    "    notsorecent_num = round((int(len(grouped.get_group('notsorecent'))) / len(diary_df)) * 15)\n",
    "    old_num = round((int(len(grouped.get_group('old'))) / len(diary_df)) * 15)\n",
    "\n",
    "    # Choose 10 random movies from the filtered DataFrame\n",
    "    recommended_movies = pd.concat([high_rated_movies1.sample(n=recent_num), high_rated_movies2.sample(n=notsorecent_num), high_rated_movies3.sample(n=old_num)], ignore_index=True)\n",
    "    \n",
    "    return recommended_movies\n",
    "\n",
    "# Call the recommendation function\n",
    "recommended_movies = recommend_movies(search_results_df1)\n",
    "recommended_movies[\"movie review\"]=recommended_movies.apply(lambda row: movie_reception(get_movie_reviews,row['movie title'],row['Release Year']),axis=1)\n",
    "recommended_movies[\"review link\"]=recommended_movies.apply(lambda row: get_rotten_tomatoes_url(row['movie title'],row['Release Year']),axis=1)\n",
    "\n",
    "# add people_watched and languages\n",
    "def people_watched(url):\n",
    "    r = f\"{url}members/\"\n",
    "    r = requests.get(r)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    soup_str = str(soup.find('a', class_=\"tooltip\"))\n",
    "    start_chr = soup_str.find('title=\"') + 7\n",
    "    end_chr = soup_str.find('people\">')-1\n",
    "    people_watched = soup_str[start_chr:end_chr]\n",
    "    return people_watched\n",
    "\n",
    "recommended_movies['people_watched'] = recommended_movies['movie_url'].apply(lambda x:people_watched(x))\n",
    "\n",
    "def find_language(url1):\n",
    "    languages=[]\n",
    "    url1=url1+\"/details/\"\n",
    "    response = requests.get(url1)\n",
    "    movie_page=response.text\n",
    "    soup = BeautifulSoup(movie_page, 'html.parser')\n",
    "    TAGS=soup.find_all('a')\n",
    "    for tag in TAGS:\n",
    "        if \"language\" in str(tag):\n",
    "            tag=tag.text\n",
    "            languages.append(tag)\n",
    "    return set(languages)\n",
    "\n",
    "recommended_movies['Language'] = recommended_movies['movie_url'].apply(find_language)\n",
    "recommended_movies1 = recommended_movies.copy()\n",
    "recommended_movies1 = recommended_movies1.drop('movie_url', axis=1)\n",
    "\n",
    "print(recommended_movies1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
